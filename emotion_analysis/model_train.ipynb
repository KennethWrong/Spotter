{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f10b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import neattext.functions as nfx\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torchtext.data import get_tokenizer\n",
    "from collections import Counter\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a64ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes=None, dtype=\"float32\"):\n",
    "    y = np.array(y, dtype=\"int\")\n",
    "    input_shape = y.shape\n",
    "\n",
    "    # Shrink the last dimension if the shape is (..., 1).\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "\n",
    "    y = y.reshape(-1)\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes), dtype=dtype)\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    output_shape = input_shape + (num_classes,)\n",
    "    categorical = np.reshape(categorical, output_shape)\n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142acce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_matrix, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super(EmotionModel, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        embedding_dim = embedding_matrix.size(1)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, _weight=embedding_matrix)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.Softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        embeds = self.embedding(x) # [1, 79, 200]\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden) # [1, 79, 128]\n",
    "        print(hidden)\n",
    "\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)  #[79, 128]\n",
    "    \n",
    "        \n",
    "        out = self.dropout(lstm_out) # [79, 128]\n",
    "        out = self.fc(out) # [79, 8]\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        out = out.view(batch_size, -1, self.output_size)\n",
    "        out = out[:, -1]  \n",
    "        out = self.Softmax(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(torch.float32).to(device),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(torch.float32).to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cccb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = pd.read_csv(\"../data/data.csv\")\n",
    "text_labels = pd.read_csv(\"../data/labels.csv\")\n",
    "\n",
    "label_emotion = text_labels['Emotion'].tolist()\n",
    "label_encoded = text_labels['emotion_encoded'].tolist()\n",
    "\n",
    "label_mapping = {idx: emotion for idx,emotion in zip(label_encoded, label_emotion)}\n",
    "vectorized_labels = to_categorical(label_encoded)\n",
    "\n",
    "sentences = text_data['Clean_Text'].tolist()\n",
    "full_doc = \" \".join([str(s) for s in sentences])\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "tokenized_doc = tokenizer(full_doc)\n",
    "\n",
    "vocab = list(set(tokenized_doc))\n",
    "\n",
    "tokens_map_wn = {token:idx+1 for idx,token in enumerate(vocab)}\n",
    "tokens_map_nw = {idx+1:token for idx,token in enumerate(vocab)}\n",
    "tokens_map_nw[0] = \"\"\n",
    "tokens_map_wn[\"\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "sentence_tokenized = [tokenizer(str(s)) for s in sentences]\n",
    "sentence_tokenized = [[tokens_map_wn[w] for w in s] for s in sentence_tokenized]\n",
    "\n",
    "max_sequence_length = max([len(s) for s in sentence_tokenized])\n",
    "vocab_size = len(vocab) + 1\n",
    "\n",
    "sentence_tokenized_p = pad_sequences(sentence_tokenized, maxlen=max_sequence_length)\n",
    "\n",
    "\n",
    "sentence_tokenized_p = np.array(sentence_tokenized_p)\n",
    "\n",
    "glove_file = \"glove.6B.200d.txt\"\n",
    "glove_path = \"../data/glove/\" + glove_file\n",
    "\n",
    "glove = {}\n",
    "\n",
    "with open(glove_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        glove[word] = coefs\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, 200), dtype=\"float32\")\n",
    "\n",
    "\n",
    "for token in tokenized_doc:\n",
    "    embedding_vector = glove.get(token, None)\n",
    "\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[tokens_map_wn[token]] = embedding_vector\n",
    "\n",
    "\n",
    "sentence_embedded_p = np.array([[embedding_matrix[t,:] for t in q] for q in sentence_tokenized_p.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb4369",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_labels_t = torch.Tensor(vectorized_labels).to(device)\n",
    "embedding_matrix_t = torch.Tensor(embedding_matrix).to(torch.float32).to(device)\n",
    "training_data = torch.Tensor(sentence_tokenized_p).to(torch.long).to(device)\n",
    "\n",
    "train_X, sec_X, train_y, sec_y = train_test_split(training_data, vectorized_labels_t, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc7d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def get_balance_weight(y):\n",
    "    y = torch.argmax(y, dim=1).tolist()\n",
    "    count = Counter(y)\n",
    "    count = sorted([(k,v) for k,v in count.items()])\n",
    "    count = np.array([c[1] for c in count])\n",
    "\n",
    "    return torch.Tensor(1. / count).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f798b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_matrix, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super(EmotionModel, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        embedding_dim = embedding_matrix.size(1)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, _weight=embedding_matrix)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.Softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        embeds = self.embedding(x) # [1, 79, 200]\n",
    "        lstm_out, (hidden, cell) = self.lstm(embeds, hidden) # [1, 79, 128]\n",
    "\n",
    "        # hid = self.dropout(hidden[-1,:,:])\n",
    "        # out = self.sigmoid(self.fc(hid))\n",
    "\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)  #[79, 128]\n",
    "    \n",
    "        \n",
    "        out = self.dropout(lstm_out) # [79, 128]\n",
    "        out = self.fc(out) # [79, 8]\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        out = out.view(batch_size, -1, self.output_size)\n",
    "        out = out[:, -1]  \n",
    "        \n",
    "        return out, (hidden, cell)\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(torch.float32).to(device),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(torch.float32).to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a1d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fields for the model\n",
    "model = EmotionModel(\n",
    "    vocab_size= embedding_matrix_t.shape[0],\n",
    "    output_size= vectorized_labels_t.shape[1],\n",
    "    embedding_matrix= embedding_matrix_t,\n",
    "    hidden_dim= 128,\n",
    "    n_layers= 2,\n",
    "    drop_prob=0.2\n",
    "    ).to(device=device)\n",
    "loss_fn = nn.BCELoss().to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "def train_step(epochs, dataloader, batch_size):\n",
    "    model.train()\n",
    "    h = model.init_hidden(batch_size=batch_size, device=device)\n",
    "    \n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        h = tuple([e.data for e in h])\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        output, h = model(x, h)\n",
    "        loss = loss_fn(output, y.float())\n",
    "\n",
    "        if i % 200 == 0:\n",
    "            print(output, y)\n",
    "            print(f\"Curr Loss: {loss.item()}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # break\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 4\n",
    "\n",
    "# Balancing the data set\n",
    "from collections import Counter\n",
    "count = Counter(label_encoded)\n",
    "count = sorted([(k,v) for k,v in count.items()])\n",
    "count = np.array([c[1] for c in count])\n",
    "\n",
    "weights =  get_balance_weight(train_y)\n",
    "\n",
    "sampler = WeightedRandomSampler(weights, train_X.shape[0],replacement=True)\n",
    "\n",
    "train_data = TensorDataset(train_X, train_y)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "for e in range(epochs):\n",
    "    print(f\"Epoch: {e + 1}:\")\n",
    "    train_step(e+1, train_loader, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d484f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "85873e3c2f23d47c926a81a8e94c0ccee54e84f329ff08cc51e05afe72c04afe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
